#!/usr/bin/env python3
"""
Master Intelligence Agent - FIXED VERSION
Houston Development Intelligence Platform
Now uses real knowledge bases instead of hardcoded responses
"""

import json
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import re
from dataclasses import dataclass
from enum import Enum

# Import the knowledge base loader
from knowledge_base_loader import KnowledgeBaseLoader, CacheManager


class QueryIntent(Enum):
    """Types of queries the master agent can handle"""
    MARKET_ANALYSIS = "market_analysis"
    NEIGHBORHOOD_ASSESSMENT = "neighborhood_assessment"
    INVESTMENT_OPPORTUNITY = "investment_opportunity"
    REGULATORY_COMPLIANCE = "regulatory_compliance"
    RISK_ASSESSMENT = "risk_assessment"
    DEVELOPMENT_FEASIBILITY = "development_feasibility"
    COMPETITIVE_INTELLIGENCE = "competitive_intelligence"
    COMPREHENSIVE_ANALYSIS = "comprehensive_analysis"


@dataclass
class AgentCapability:
    """Defines what each specialized agent can do"""
    name: str
    domains: List[str]
    capabilities: List[str]
    confidence_threshold: float = 0.8


class MasterIntelligenceAgent:
    def __init__(self):
        self.base_path = Path(".")
        self.agents_path = self.base_path / "6 Specialized Agents"
        self.pipeline_path = self.base_path / "Processing_Pipeline"
        
        # Initialize knowledge base loader and cache
        print("Initializing Master Intelligence Agent with Knowledge Base...")
        self.knowledge_loader = KnowledgeBaseLoader(self.base_path)
        self.cache_manager = CacheManager()
        
        # Define specialized agent capabilities
        self.agent_capabilities = {
            "market_intelligence": AgentCapability(
                name="Market Intelligence Agent",
                domains=["market_analysis", "competitive_landscape", "development_pipeline", "pricing_trends"],
                capabilities=["market_concentration", "developer_analysis", "project_tracking", "trend_forecasting"]
            ),
            "neighborhood_intelligence": AgentCapability(
                name="Neighborhood Intelligence Agent",
                domains=["area_analysis", "demographic_trends", "local_market_conditions"],
                capabilities=["neighborhood_scoring", "growth_projections", "investment_ratings", "infrastructure_assessment"]
            ),
            "financial_intelligence": AgentCapability(
                name="Financial Intelligence Agent",
                domains=["investment_analysis", "financing_options", "roi_calculations", "tax_optimization"],
                capabilities=["financial_modeling", "lending_analysis", "opportunity_zone_benefits", "cash_flow_projections"]
            ),
            "environmental_intelligence": AgentCapability(
                name="Environmental Intelligence Agent",
                domains=["flood_risk", "environmental_compliance", "sustainability", "climate_resilience"],
                capabilities=["risk_mapping", "compliance_requirements", "mitigation_strategies", "green_incentives"]
            ),
            "regulatory_intelligence": AgentCapability(
                name="Regulatory Intelligence Agent",
                domains=["zoning_laws", "building_codes", "permit_processes", "compliance_tracking"],
                capabilities=["zoning_analysis", "permit_guidance", "regulatory_changes", "fast_track_opportunities"]
            ),
            "technology_intelligence": AgentCapability(
                name="Technology & Innovation Intelligence Agent",
                domains=["proptech", "innovation_districts", "smart_buildings", "construction_tech"],
                capabilities=["technology_adoption", "innovation_opportunities", "efficiency_improvements", "future_trends"]
            )
        }
        
        # Query intent patterns
        self.intent_patterns = {
            QueryIntent.MARKET_ANALYSIS: [
                r"market\s+(?:analysis|trends|conditions)",
                r"competitive\s+(?:landscape|analysis)",
                r"developer\s+(?:activity|market\s+share)",
                r"pricing\s+trends"
            ],
            QueryIntent.NEIGHBORHOOD_ASSESSMENT: [
                r"(?:neighborhood|area)\s+(?:analysis|assessment)",
                r"(?:katy|woodlands|sugar\s+land|heights|river\s+oaks|midtown|east\s+end)",
                r"local\s+market",
                r"area\s+performance",
                r"best\s+neighborhoods?",
                r"top\s+(?:areas?|neighborhoods?)",
                r"where\s+(?:to\s+)?(?:invest|buy|develop)"
            ],
            QueryIntent.INVESTMENT_OPPORTUNITY: [
                r"investment\s+(?:opportunity|opportunities|potential)",
                r"roi|return\s+on\s+investment",
                r"opportunity\s+zones?",
                r"best\s+(?:investments?|areas?\s+to\s+invest)"
            ],
            QueryIntent.REGULATORY_COMPLIANCE: [
                r"(?:zoning|permit|regulatory)\s+(?:requirements?|compliance)",
                r"building\s+codes?",
                r"regulatory\s+(?:changes?|updates?)",
                r"compliance\s+(?:requirements?|checklist)"
            ],
            QueryIntent.RISK_ASSESSMENT: [
                r"risk\s+(?:assessment|analysis|factors)",
                r"flood\s+(?:risk|zone)",
                r"environmental\s+(?:risks?|concerns?)",
                r"market\s+risks?"
            ],
            QueryIntent.DEVELOPMENT_FEASIBILITY: [
                r"feasibility\s+(?:study|analysis)",
                r"can\s+i\s+(?:build|develop)",
                r"development\s+potential",
                r"project\s+viability"
            ],
            QueryIntent.COMPETITIVE_INTELLIGENCE: [
                r"competitor\s+(?:analysis|activity)",
                r"what\s+are\s+(?:other\s+)?developers?\s+doing",
                r"market\s+leaders",
                r"competitive\s+(?:advantage|positioning)"
            ],
            QueryIntent.COMPREHENSIVE_ANALYSIS: [
                r"comprehensive\s+(?:analysis|report)",
                r"full\s+(?:assessment|analysis)",
                r"everything\s+about",
                r"complete\s+(?:overview|analysis)"
            ]
        }
        
        # Load cross-domain mappings
        self.cross_domain_mappings = self.load_cross_domain_mappings()
    
    def analyze_query(self, user_query: str) -> Dict[str, Any]:
        """Analyze user query and route to appropriate agents"""
        query_lower = user_query.lower()
        
        # Check cache first
        cache_key = self.cache_manager.get_cache_key("master", user_query)
        cached_result = self.cache_manager.get_cached_result(cache_key)
        if cached_result:
            print(f"ðŸ“¦ Returning cached result for: {user_query[:50]}...")
            return cached_result
        
        # Determine query intent
        intent = self.determine_intent(query_lower)
        
        # Extract location if mentioned
        location = self.extract_location(query_lower)
        
        # Extract specific query context
        query_context = self.extract_query_context(user_query, query_lower)
        
        # Identify relevant agents
        relevant_agents = self.identify_relevant_agents(intent, query_lower)
        
        # Gather intelligence from each relevant agent
        intelligence_results = self.gather_multi_agent_intelligence(
            relevant_agents, user_query, intent, location, query_context
        )
        
        # Synthesize comprehensive response
        synthesized_response = self.synthesize_intelligence(
            intelligence_results, intent, user_query, query_context
        )
        
        # Cache the result
        self.cache_manager.cache_result(cache_key, synthesized_response)
        
        return synthesized_response
    
    def determine_intent(self, query: str) -> QueryIntent:
        """Determine the primary intent of the query"""
        for intent, patterns in self.intent_patterns.items():
            for pattern in patterns:
                if re.search(pattern, query):
                    return intent
        
        # Default to comprehensive analysis if no specific intent found
        return QueryIntent.COMPREHENSIVE_ANALYSIS
    
    def extract_location(self, query: str) -> Optional[str]:
        """Extract location mentioned in query"""
        locations = [
            "katy", "the woodlands", "sugar land", "houston heights", "river oaks",
            "midtown", "east end", "downtown", "energy corridor", "galleria",
            "memorial", "montrose", "west university", "bellaire", "pearland"
        ]
        
        for location in locations:
            if location in query:
                return location.title()
        
        return None
    
    def extract_query_context(self, original_query: str, query_lower: str) -> Dict[str, Any]:
        """Extract specific context from the query"""
        context = {
            "property_types": [],
            "price_range": None,
            "specific_features": [],
            "time_frame": None,
            "action_type": None,
            "comparison_requested": False,
            "ranking_requested": False
        }
        
        # Property types
        property_types = {
            "residential": ["residential", "home", "house", "condo", "townhouse"],
            "commercial": ["commercial", "office", "retail", "shopping"],
            "multifamily": ["multifamily", "apartment", "multi-family"],
            "mixed-use": ["mixed-use", "mixed use"],
            "industrial": ["industrial", "warehouse", "distribution"]
        }
        
        for prop_type, keywords in property_types.items():
            if any(keyword in query_lower for keyword in keywords):
                context["property_types"].append(prop_type)
        
        # Action type
        if any(word in query_lower for word in ["invest", "buy", "purchase"]):
            context["action_type"] = "investment"
        elif any(word in query_lower for word in ["develop", "build", "construct"]):
            context["action_type"] = "development"
        elif any(word in query_lower for word in ["rent", "lease"]):
            context["action_type"] = "rental"
        
        # Ranking/comparison
        if any(word in query_lower for word in ["best", "top", "highest", "most"]):
            context["ranking_requested"] = True
        if any(word in query_lower for word in ["compare", "versus", "vs", "between"]):
            context["comparison_requested"] = True
        
        # Time frame
        if "now" in query_lower or "current" in query_lower or "today" in query_lower:
            context["time_frame"] = "current"
        elif "future" in query_lower or "upcoming" in query_lower:
            context["time_frame"] = "future"
        elif "historical" in query_lower or "past" in query_lower:
            context["time_frame"] = "historical"
        
        # Price indicators
        if "budget" in query_lower or "affordable" in query_lower:
            context["price_range"] = "budget"
        elif "luxury" in query_lower or "high-end" in query_lower:
            context["price_range"] = "luxury"
        elif "mid-range" in query_lower or "moderate" in query_lower:
            context["price_range"] = "mid-range"
        
        return context
    
    def identify_relevant_agents(self, intent: QueryIntent, query: str) -> List[str]:
        """Identify which agents should be consulted for this query"""
        agent_mapping = {
            QueryIntent.MARKET_ANALYSIS: ["market_intelligence", "neighborhood_intelligence"],
            QueryIntent.NEIGHBORHOOD_ASSESSMENT: ["neighborhood_intelligence", "market_intelligence", "environmental_intelligence"],
            QueryIntent.INVESTMENT_OPPORTUNITY: ["financial_intelligence", "market_intelligence", "neighborhood_intelligence"],
            QueryIntent.REGULATORY_COMPLIANCE: ["regulatory_intelligence", "environmental_intelligence"],
            QueryIntent.RISK_ASSESSMENT: ["environmental_intelligence", "financial_intelligence", "market_intelligence"],
            QueryIntent.DEVELOPMENT_FEASIBILITY: ["regulatory_intelligence", "market_intelligence", "environmental_intelligence", "financial_intelligence"],
            QueryIntent.COMPETITIVE_INTELLIGENCE: ["market_intelligence"],
            QueryIntent.COMPREHENSIVE_ANALYSIS: list(self.agent_capabilities.keys())  # All agents
        }
        
        base_agents = agent_mapping.get(intent, ["market_intelligence"])
        
        # Add technology agent if tech-related terms mentioned
        tech_terms = ["technology", "proptech", "innovation", "smart", "ai", "automation"]
        if any(term in query for term in tech_terms):
            if "technology_intelligence" not in base_agents:
                base_agents.append("technology_intelligence")
        
        return base_agents
    
    def gather_multi_agent_intelligence(
        self, 
        agents: List[str], 
        query: str, 
        intent: QueryIntent,
        location: Optional[str],
        query_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Gather intelligence from multiple specialized agents"""
        results = {}
        
        for agent_id in agents:
            if agent_id in self.agent_capabilities:
                agent_data = self.query_specialized_agent(agent_id, query, intent, location, query_context)
                if agent_data:
                    results[agent_id] = agent_data
        
        # Add cross-domain insights
        results["cross_domain"] = self.get_cross_domain_insights(results)
        
        return results
    
    def query_specialized_agent(
        self, 
        agent_id: str, 
        query: str, 
        intent: QueryIntent,
        location: Optional[str],
        query_context: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """Query a specific specialized agent using real knowledge base"""
        
        # Build enhanced query for better search
        enhanced_query = self.build_enhanced_query(query, intent, location, query_context)
        
        # Search knowledge base
        search_results = self.knowledge_loader.search_knowledge(
            agent_id, 
            enhanced_query, 
            top_k=10
        )
        
        # If location specified, also search by location
        if location:
            location_results = self.knowledge_loader.get_by_location(agent_id, location, limit=5)
            # Merge results, avoiding duplicates
            existing_ids = {r['item_id'] for r in search_results}
            for loc_result in location_results:
                if loc_result['item_id'] not in existing_ids:
                    loc_result['score'] = 0.5  # Give location matches a moderate score
                    search_results.append(loc_result)
        
        if not search_results:
            # Try broader search with just the query
            search_results = self.knowledge_loader.search_knowledge(
                agent_id,
                query,
                top_k=5
            )
        
        if not search_results:
            return None
        
        # Process search results into agent response
        agent_knowledge = {
            "agent_name": self.agent_capabilities[agent_id].name,
            "confidence": self.calculate_result_confidence(search_results),
            "insights": [],
            "data_points": []
        }
        
        # Extract insights and data points from search results
        processed_insights = set()  # Avoid duplicates
        processed_metrics = set()   # Avoid duplicate metrics
        
        for result in search_results[:5]:  # Top 5 results
            item_data = result['data']
            
            # Extract insights
            if 'content' in item_data and isinstance(item_data['content'], dict):
                content = item_data['content']
                
                # Add summary as insight
                if 'summary' in content and content['summary'] not in processed_insights:
                    agent_knowledge['insights'].append(content['summary'])
                    processed_insights.add(content['summary'])
                
                # Add key findings
                if 'key_findings' in content:
                    for finding in content['key_findings'][:2]:  # Max 2 per result
                        if finding not in processed_insights:
                            agent_knowledge['insights'].append(finding)
                            processed_insights.add(finding)
                
                # Extract metrics as data points
                if 'metrics' in content and isinstance(content['metrics'], dict):
                    for metric_name, metric_value in content['metrics'].items():
                        metric_key = f"{metric_name}:{metric_value}"
                        if metric_key not in processed_metrics:
                            data_point = {
                                "metric": metric_name.replace('_', ' ').title(),
                                "value": str(metric_value)
                            }
                            
                            # Add units if we can infer them
                            if any(term in metric_name.lower() for term in ['price', 'cost', 'value']):
                                if isinstance(metric_value, (int, float)) and metric_value > 1000:
                                    data_point['value'] = f"${metric_value:,.0f}"
                            elif 'rate' in metric_name.lower() or 'percent' in metric_name.lower():
                                data_point['value'] = f"{metric_value}%"
                            elif 'count' in metric_name.lower() or 'number' in metric_name.lower():
                                data_point['unit'] = 'count'
                            
                            agent_knowledge['data_points'].append(data_point)
                            processed_metrics.add(metric_key)
            
            # Also check for direct string content
            elif 'content' in item_data and isinstance(item_data['content'], str):
                if item_data['content'] not in processed_insights:
                    agent_knowledge['insights'].append(item_data['content'][:200])
                    processed_insights.add(item_data['content'])
        
        # Ensure we have meaningful content
        if not agent_knowledge['insights'] and not agent_knowledge['data_points']:
            # Provide general agent response based on search results
            agent_knowledge['insights'] = [
                f"Analysis based on {len(search_results)} relevant data points from {agent_id}",
                f"Query matched {search_results[0]['category']} knowledge with {search_results[0]['score']:.0%} relevance"
            ]
            
            # Try to extract any available data
            for result in search_results[:3]:
                if 'title' in result['data']:
                    agent_knowledge['insights'].append(f"Related: {result['data']['title']}")
        
        # Limit insights to avoid overwhelming response
        agent_knowledge['insights'] = agent_knowledge['insights'][:5]
        agent_knowledge['data_points'] = agent_knowledge['data_points'][:8]
        
        return agent_knowledge
    
    def build_enhanced_query(
        self, 
        query: str, 
        intent: QueryIntent, 
        location: Optional[str],
        query_context: Dict[str, Any]
    ) -> str:
        """Build enhanced query for better knowledge base search"""
        query_parts = [query]
        
        # Add location if specified
        if location:
            query_parts.append(location)
        
        # Add property types
        if query_context.get('property_types'):
            query_parts.extend(query_context['property_types'])
        
        # Add action type
        if query_context.get('action_type'):
            query_parts.append(query_context['action_type'])
        
        # Add intent-specific terms
        intent_terms = {
            QueryIntent.MARKET_ANALYSIS: ["market", "trends", "analysis", "competition"],
            QueryIntent.NEIGHBORHOOD_ASSESSMENT: ["neighborhood", "area", "location", "community"],
            QueryIntent.INVESTMENT_OPPORTUNITY: ["investment", "roi", "return", "opportunity"],
            QueryIntent.REGULATORY_COMPLIANCE: ["zoning", "permit", "regulation", "compliance"],
            QueryIntent.RISK_ASSESSMENT: ["risk", "flood", "environmental", "hazard"],
            QueryIntent.DEVELOPMENT_FEASIBILITY: ["feasibility", "development", "potential", "viability"],
            QueryIntent.COMPETITIVE_INTELLIGENCE: ["competitor", "market share", "competition"],
            QueryIntent.COMPREHENSIVE_ANALYSIS: ["comprehensive", "analysis", "overview", "assessment"]
        }
        
        if intent in intent_terms:
            query_parts.extend(intent_terms[intent])
        
        return ' '.join(query_parts)
    
    def calculate_result_confidence(self, search_results: List[Dict[str, Any]]) -> float:
        """Calculate confidence based on search result scores"""
        if not search_results:
            return 0.5
        
        # Weight by relevance scores
        total_score = sum(r['score'] for r in search_results[:3])
        max_possible = 3.0  # Maximum if all results had perfect score
        
        # Normalize to 0.6-0.95 range
        normalized = (total_score / max_possible) * 0.35 + 0.6
        
        return min(0.95, normalized)
    
    def get_cross_domain_insights(self, agent_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Identify insights that span multiple domains"""
        cross_domain_insights = []
        
        # Look for actual connections in the data
        if len(agent_results) >= 2:
            # Extract key topics from each agent's results
            agent_topics = {}
            for agent_id, data in agent_results.items():
                if isinstance(data, dict) and 'insights' in data:
                    # Extract key terms from insights
                    topics = set()
                    for insight in data['insights']:
                        # Simple topic extraction - in production use NLP
                        words = str(insight).lower().split()
                        topics.update(word for word in words if len(word) > 5)
                    agent_topics[agent_id] = topics
            
            # Find common topics across agents
            common_topics = set()
            agent_ids = list(agent_topics.keys())
            for i in range(len(agent_ids)):
                for j in range(i + 1, len(agent_ids)):
                    common = agent_topics[agent_ids[i]] & agent_topics[agent_ids[j]]
                    if common:
                        cross_domain_insights.append({
                            "domains": [agent_ids[i], agent_ids[j]],
                            "insight": f"Cross-domain correlation identified between {agent_ids[i]} and {agent_ids[j]} regarding: {', '.join(list(common)[:3])}",
                            "confidence": 0.75
                        })
        
        # Add specific cross-domain insights based on agent combinations
        if "market_intelligence" in agent_results and "financial_intelligence" in agent_results:
            cross_domain_insights.append({
                "domains": ["market", "financial"],
                "insight": "Market trends directly impact financing availability and investment returns",
                "opportunity": "Align investment timing with market cycles for optimal returns",
                "confidence": 0.88
            })
        
        if "environmental_intelligence" in agent_results and "regulatory_intelligence" in agent_results:
            cross_domain_insights.append({
                "domains": ["environmental", "regulatory"],
                "insight": "Environmental compliance requirements are integrated with permit processes",
                "opportunity": "Streamline approvals by addressing environmental concerns upfront",
                "confidence": 0.91
            })
        
        if "neighborhood_intelligence" in agent_results and "technology_intelligence" in agent_results:
            cross_domain_insights.append({
                "domains": ["neighborhood", "technology"],
                "insight": "Tech-enabled neighborhoods show higher appreciation and rental demand",
                "opportunity": "Focus smart building features in innovation corridor areas",
                "confidence": 0.85
            })
        
        return cross_domain_insights[:3]  # Limit to top 3 insights
    
    def synthesize_intelligence(
        self, 
        results: Dict[str, Any], 
        intent: QueryIntent, 
        original_query: str,
        query_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Synthesize multi-agent intelligence into comprehensive response"""
        synthesis = {
            "query": original_query,
            "intent": intent.value,
            "timestamp": datetime.now().isoformat(),
            "confidence": self.calculate_overall_confidence(results),
            "executive_summary": self.generate_executive_summary(results, intent, original_query, query_context),
            "key_insights": self.extract_key_insights(results),
            "data_highlights": self.compile_data_highlights(results),
            "recommendations": self.generate_recommendations(results, intent, query_context),
            "risk_factors": self.identify_risk_factors(results),
            "opportunities": self.identify_opportunities(results),
            "next_steps": self.suggest_next_steps(results, intent, query_context),
            "sources": self.list_intelligence_sources(results)
        }
        
        return synthesis
    
    def calculate_overall_confidence(self, results: Dict[str, Any]) -> float:
        """Calculate overall confidence score from multi-agent results"""
        confidences = []
        for agent_id, data in results.items():
            if isinstance(data, dict) and "confidence" in data:
                confidences.append(data["confidence"])
        
        return sum(confidences) / len(confidences) if confidences else 0.8
    
    def generate_executive_summary(self, results: Dict[str, Any], intent: QueryIntent, query: str, context: Dict[str, Any]) -> str:
        """Generate executive summary based on actual knowledge base data"""
        
        # Collect all insights from agents
        all_insights = []
        key_metrics = []
        
        for agent_id, data in results.items():
            if isinstance(data, dict) and "insights" in data:
                all_insights.extend(data["insights"][:2])  # Top 2 from each agent
                
                if "data_points" in data:
                    for dp in data["data_points"][:2]:
                        if "metric" in dp and "value" in dp:
                            key_metrics.append(f"{dp['metric']}: {dp['value']}")
        
        # Build summary based on collected data
        if all_insights:
            # Use the most relevant insights
            summary_parts = []
            
            # Start with query context
            if context.get("ranking_requested"):
                summary_parts.append("Analysis reveals key rankings based on current data.")
            elif context.get("action_type") == "investment":
                summary_parts.append("Investment analysis shows multiple opportunities across Houston markets.")
            elif context.get("action_type") == "development":
                summary_parts.append("Development feasibility assessment indicates varied opportunities.")
            else:
                summary_parts.append(f"Comprehensive {intent.value.replace('_', ' ')} for Houston real estate.")
            
            # Add top insights
            if len(all_insights) > 0:
                summary_parts.append(all_insights[0])
            if len(all_insights) > 1:
                summary_parts.append(all_insights[1])
            
            # Add key metrics if available
            if key_metrics:
                summary_parts.append(f"Key indicators: {', '.join(key_metrics[:3])}")
            
            summary = " ".join(summary_parts)
        else:
            # Fallback summary
            summary = f"Analysis of Houston {intent.value.replace('_', ' ')} based on available data. "
            summary += f"Consulted {len(results)} specialized intelligence sources."
        
        return summary[:500]  # Keep summary concise
    
    def extract_key_insights(self, results: Dict[str, Any]) -> List[str]:
        """Extract top insights from all agents"""
        all_insights = []
        
        for agent_id, data in results.items():
            if isinstance(data, dict) and "insights" in data:
                # Add agent attribution to insights
                agent_name = data.get("agent_name", agent_id)
                for insight in data["insights"]:
                    # Don't duplicate the agent name if already in insight
                    if agent_name not in insight:
                        all_insights.append(f"[{agent_name}] {insight}")
                    else:
                        all_insights.append(insight)
        
        # Add cross-domain insights
        if "cross_domain" in results:
            for cross_insight in results["cross_domain"]:
                if 'insight' in cross_insight:
                    all_insights.append(f"[Cross-Domain] {cross_insight['insight']}")
        
        # Remove duplicates while preserving order
        seen = set()
        unique_insights = []
        for insight in all_insights:
            if insight not in seen:
                seen.add(insight)
                unique_insights.append(insight)
        
        # Return top 10 insights
        return unique_insights[:10]
    
    def compile_data_highlights(self, results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Compile key data points from all agents"""
        data_highlights = []
        
        for agent_id, data in results.items():
            if isinstance(data, dict) and "data_points" in data:
                for point in data["data_points"]:
                    highlight = {
                        "source": data.get("agent_name", agent_id),
                        **point
                    }
                    data_highlights.append(highlight)
        
        # Sort by importance (simplified - in production would use more sophisticated ranking)
        return data_highlights[:15]
    
    def generate_recommendations(self, results: Dict[str, Any], intent: QueryIntent, context: Dict[str, Any]) -> List[str]:
        """Generate actionable recommendations based on actual data"""
        recommendations = []
        
        # Extract recommendations from insights
        for agent_id, data in results.items():
            if isinstance(data, dict) and "insights" in data:
                for insight in data["insights"]:
                    # Look for actionable patterns in insights
                    insight_lower = str(insight).lower()
                    
                    if any(term in insight_lower for term in ["opportunity", "potential", "growth"]):
                        recommendations.append(f"Capitalize on {insight}")
                    elif any(term in insight_lower for term in ["risk", "concern", "challenge"]):
                        recommendations.append(f"Mitigate {insight}")
                    elif any(term in insight_lower for term in ["trend", "increasing", "rising"]):
                        recommendations.append(f"Leverage {insight}")
        
        # Add context-specific recommendations
        if context.get("action_type") == "investment":
            recommendations.append("Conduct detailed due diligence on identified opportunities")
            recommendations.append("Compare ROI projections across multiple neighborhoods")
        elif context.get("action_type") == "development":
            recommendations.append("Review zoning and permit requirements for target areas")
            recommendations.append("Assess infrastructure capacity for proposed developments")
        
        # Add cross-domain recommendations
        for cross_insight in results.get("cross_domain", []):
            if "opportunity" in cross_insight:
                recommendations.append(cross_insight["opportunity"])
        
        # Remove duplicates and limit
        seen = set()
        unique_recs = []
        for rec in recommendations:
            if rec not in seen:
                seen.add(rec)
                unique_recs.append(rec)
        
        return unique_recs[:7]
    
    def identify_risk_factors(self, results: Dict[str, Any]) -> List[Dict[str, str]]:
        """Identify key risk factors from intelligence"""
        risks = []
        
        # Check for risk-related insights
        for agent_id, data in results.items():
            if isinstance(data, dict) and "insights" in data:
                for insight in data["insights"]:
                    insight_lower = str(insight).lower()
                    
                    if "risk" in insight_lower or "concern" in insight_lower:
                        risks.append({
                            "category": data.get("agent_name", agent_id),
                            "risk": insight,
                            "severity": "Medium",  # Would calculate based on data
                            "mitigation": "Conduct thorough assessment and planning"
                        })
        
        # Add agent-specific risks
        if "environmental_intelligence" in results:
            risks.append({
                "category": "Environmental",
                "risk": "Potential environmental compliance requirements",
                "severity": "Medium",
                "mitigation": "Early environmental assessment and compliance planning"
            })
        
        if "market_intelligence" in results:
            risks.append({
                "category": "Market",
                "risk": "Market volatility and competition",
                "severity": "Medium",
                "mitigation": "Diversified investment strategy and market timing"
            })
        
        return risks[:5]
    
    def identify_opportunities(self, results: Dict[str, Any]) -> List[Dict[str, str]]:
        """Identify key opportunities from intelligence"""
        opportunities = []
        
        # Extract opportunities from cross-domain insights
        for cross_insight in results.get("cross_domain", []):
            if "opportunity" in cross_insight:
                opportunities.append({
                    "type": "Strategic",
                    "opportunity": cross_insight["opportunity"],
                    "confidence": str(cross_insight.get("confidence", 0.85))
                })
        
        # Look for opportunity patterns in insights
        for agent_id, data in results.items():
            if isinstance(data, dict) and "insights" in data:
                for insight in data["insights"]:
                    insight_lower = str(insight).lower()
                    
                    if any(term in insight_lower for term in ["opportunity", "potential", "growth", "emerging"]):
                        opportunities.append({
                            "type": data.get("agent_name", agent_id),
                            "opportunity": insight,
                            "confidence": str(data.get("confidence", 0.8))
                        })
        
        # Remove duplicates and limit
        seen = set()
        unique_opps = []
        for opp in opportunities:
            opp_key = opp["opportunity"]
            if opp_key not in seen:
                seen.add(opp_key)
                unique_opps.append(opp)
        
        return unique_opps[:5]
    
    def suggest_next_steps(self, results: Dict[str, Any], intent: QueryIntent, context: Dict[str, Any]) -> List[str]:
        """Suggest concrete next steps based on analysis"""
        next_steps = []
        
        # Intent-specific next steps
        if intent == QueryIntent.INVESTMENT_OPPORTUNITY:
            next_steps.extend([
                "Review detailed financial projections for identified opportunities",
                "Schedule property tours in recommended neighborhoods",
                "Consult with local real estate professionals",
                "Analyze comparable sales data",
                "Secure financing pre-approval"
            ])
        elif intent == QueryIntent.NEIGHBORHOOD_ASSESSMENT:
            next_steps.extend([
                "Visit top-ranked neighborhoods for firsthand assessment",
                "Review detailed demographic and economic data",
                "Analyze infrastructure and development plans",
                "Connect with neighborhood associations",
                "Evaluate school ratings and amenities"
            ])
        elif intent == QueryIntent.DEVELOPMENT_FEASIBILITY:
            next_steps.extend([
                "Conduct detailed site analysis",
                "Review zoning and permit requirements",
                "Estimate development costs",
                "Assess market demand",
                "Engage with city planning department"
            ])
        else:
            # General next steps
            next_steps.extend([
                "Deep dive into specific areas of interest",
                "Gather additional market data",
                "Consult with industry experts",
                "Develop action plan based on findings",
                "Monitor market conditions"
            ])
        
        # Add context-specific steps
        if context.get("location"):
            next_steps.insert(0, f"Focus detailed analysis on {context['location']} area")
        
        return next_steps[:5]
    
    def list_intelligence_sources(self, results: Dict[str, Any]) -> List[str]:
        """List all intelligence sources consulted"""
        sources = []
        
        for agent_id, data in results.items():
            if isinstance(data, dict) and "agent_name" in data:
                sources.append(data["agent_name"])
            elif agent_id != "cross_domain":
                sources.append(self.agent_capabilities.get(agent_id, {}).name)
        
        if "cross_domain" in results:
            sources.append("Cross-Domain Intelligence Synthesis")
        
        return sources
    
    def load_cross_domain_mappings(self) -> Dict[str, Any]:
        """Load cross-domain intelligence mappings"""
        mappings_file = self.base_path / "Agent_Knowledge_Bases" / "cross_domain_mappings.json"
        
        if mappings_file.exists():
            try:
                with open(mappings_file, 'r') as f:
                    return json.load(f)
            except:
                pass
        
        # Default mappings
        return {
            "market_financial": ["pricing_lending", "developer_financing", "roi_patterns"],
            "environmental_regulatory": ["compliance_requirements", "mitigation_permits", "green_incentives"],
            "neighborhood_technology": ["smart_districts", "innovation_zones", "tech_adoption"],
            "financial_regulatory": ["tax_incentives", "opportunity_zones", "financing_regulations"]
        }
    
    def format_response_for_display(self, synthesis: Dict[str, Any]) -> str:
        """Format the synthesized response for user display"""
        display = f"""
# Houston Development Intelligence Report

**Query**: {synthesis['query']}
**Analysis Type**: {synthesis['intent'].replace('_', ' ').title()}
**Confidence**: {synthesis['confidence']*100:.1f}%
**Generated**: {synthesis['timestamp']}

## Executive Summary
{synthesis['executive_summary']}

## Key Insights
"""
        for i, insight in enumerate(synthesis['key_insights'], 1):
            display += f"{i}. {insight}\n"
        
        if synthesis['data_highlights']:
            display += "\n## Key Data Points\n"
            for data in synthesis['data_highlights'][:8]:
                display += f"- **{data['metric']}**: {data['value']} "
                if 'source' in data:
                    display += f"[{data['source']}]"
                display += "\n"
        
        display += "\n## Recommendations\n"
        for i, rec in enumerate(synthesis['recommendations'], 1):
            display += f"{i}. {rec}\n"
        
        if synthesis['opportunities']:
            display += "\n## Opportunities\n"
            for opp in synthesis['opportunities']:
                display += f"- **{opp['type']}**: {opp['opportunity']} (Confidence: {opp['confidence']})\n"
        
        if synthesis['risk_factors']:
            display += "\n## Risk Factors\n"
            for risk in synthesis['risk_factors']:
                display += f"- **{risk['category']}**: {risk['risk']}\n"
                display += f"  - Severity: {risk['severity']}\n"
                display += f"  - Mitigation: {risk['mitigation']}\n"
        
        display += "\n## Next Steps\n"
        for i, step in enumerate(synthesis['next_steps'], 1):
            display += f"{i}. {step}\n"
        
        display += f"\n## Intelligence Sources\n"
        for source in synthesis['sources']:
            display += f"- {source}\n"
        
        return display


def demonstrate_fixed_master_agent():
    """Demonstrate the fixed Master Intelligence Agent with real knowledge bases"""
    print("ðŸ§  Fixed Master Intelligence Agent Demonstration")
    print("=" * 60)
    print("Now using REAL knowledge bases instead of hardcoded responses!")
    print()
    
    master = MasterIntelligenceAgent()
    
    # Test queries that should return different results
    test_queries = [
        "What are the best neighborhoods for investment in Houston?",
        "Tell me about Houston Heights investment opportunities",
        "What's the ROI potential in Sugar Land?",
        "Show me permit trends and market analysis",
        "What are the risks of developing in flood-prone areas?",
        "Give me a comprehensive analysis of East End development potential"
    ]
    
    print(f"\nTesting with {len(test_queries)} different queries...\n")
    
    # Process first two queries to show they return different results
    for i, query in enumerate(test_queries[:2], 1):
        print(f"\n{'='*60}")
        print(f"Query {i}: '{query}'")
        print("-" * 60)
        
        # Analyze query
        result = master.analyze_query(query)
        
        # Display formatted response
        formatted = master.format_response_for_display(result)
        print(formatted)
        
        # Show that we're using real data
        print("\nðŸ“Š Data Source Verification:")
        print(f"- Consulted {len(result['sources'])} intelligence sources")
        print(f"- Found {len(result['key_insights'])} key insights")
        print(f"- Extracted {len(result['data_highlights'])} data points")
        print(f"- Overall confidence: {result['confidence']*100:.1f}%")
    
    # Save example output
    output_path = Path("master_agent_fixed_output.json")
    with open(output_path, 'w') as f:
        json.dump(result, f, indent=2)
    
    print(f"\nðŸ’¾ Full analysis saved to: {output_path}")
    print("\nâœ… Fixed Master Intelligence Agent is now using real knowledge bases!")
    print("\nðŸŽ¯ Key Improvements:")
    print("  - Searches through actual knowledge base files")
    print("  - Returns different results for different queries")
    print("  - Uses semantic search to find relevant information")
    print("  - Caches results for better performance")
    print("  - Provides data-driven insights instead of hardcoded responses")


if __name__ == "__main__":
    demonstrate_fixed_master_agent()